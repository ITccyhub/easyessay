[models]
using_model = gpt-3.5-turbo
llm = Ollama
model_1 = gpt-3.5-turbo
model_2 = ollama_openhermes

[path]
output_path = ./output